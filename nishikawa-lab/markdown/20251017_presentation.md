---
marp: true
title: "CNN - aohon; chapter 5.9, 5.10"
paginate: false 
theme: arxiv_plain
---

教科書  
5.9, 5.10章 (p108–p123)

---

## 画像生成・補完に向けた拡大CNNの導入
ここまでは「変わらない / ダウンサンプリング」を扱ったが、画像を生成・補完する場合はサイズを拡大するCNNが必要。

- 空間方向のサイズとは: width × height（画像サイズ）
- タスク例:
  - コンパクトなベクトルから画像を生成（1×1×K → 2×2×(K/2) → … → W×H×1）
  - セグメンテーション（W×H×1 → … → 1×1×K → … → W×H×1）

> 図提案: エンコーダ（縮小）→ ボトルネック → デコーダ（拡大）の全体ブロック図

---

## アップサンプリング＋補完＋畳み込みの基本
サイズ拡大の最も単純な方法は、アップサンプリングと補完をペアで使い、その後に畳み込みを行う。

1. 画素値 $x_{ij}$ を r 画素間隔でとびとびに再配置（アップサンプリング）
2. 間の画素を補完（この時点で画像が r 倍）
3. 畳み込み（フィルタは学習対象）


---

## 転置畳み込み（アップコンボリューション）
アップサンプリング＋畳み込みの組を使わず、補完を不要とする方法が転置畳み込み

- 形式的には、通常の畳み込みが $u = W x$ なら、転置畳み込みは $x = W^T u$
- ただし **$W^T$ は $W^{-1}$ ではなく、逆演算ではない**
- 入力に stride ごとに0を挿入して畳み込みするイメージ
- 出力サイズは次式で表せる：
  $$
  H_{out} = (H_{in} - 1) \times s - 2p + k + \text{output\_padding}
  $$
- チェッカーボードアーティファクトに注意（→後述）

> 図提案: stride=2 の zero-insertion 例と畳み込み出力

---

## サブピクセル畳み込み（PixelShuffle）
転置畳み込みとは別に、チャネル方向を空間方向に再配置して拡大する方法。

- 通常の畳み込みで $r^2 C$ チャネルを出力
- それを **チャネル→空間に並べ替え**（再配置）して倍率 $r$ 倍 に拡大
- フィルタサイズは r とは無関係（条件は「出力チャネル数が $r^2$ の倍数」）
- ICNR初期化などと組み合わせるとアーティファクトを低減できる

> 図提案: チャネル→空間変換のイラスト

---

## stride と zero-insertion の1次元での例
通常の畳み込み（stride=2）はピクセルを間引く

- 入力: [1, 2, 3, 4], フィルタ: [1, 1], stride=2 → 出力: [3, 7]

転置畳み込み（stride=2）はピクセル間に「0」を挿入（zero-insertion）。

- 入力: [3, 7]
- stride=2 で拡大 → [3, 0, 7, 0]
- フィルタ [1, 1] で畳み込み → [3, 3, 7, 7]  
  ※ この結果は「same」相当のパディングを仮定した場合。実際は設定により異なる。

> 注意: カーネル・パディング設定によりチェッカーボードが発生することがある

---

## チェッカーボードアーティファクト対策
- resize（最近傍 / 双一次）→ 通常畳み込み  
- ConvTransposeで **kernel size を stride の倍数**に  
- PixelShuffle + **ICNR初期化**  
- `output_padding` の乱用を避ける

---

## 拡大畳み込みと「縮小→拡大」の等価性
- ダウンサンプリング→畳み込み→アップサンプリング
- 1回の拡大畳み込み
上記の二つは条件付きで近似可能。

- 手順A: 入力 x をダウンサンプリング (1/r) → フィルタ h を畳み込み → アップサンプリング (r)
- 手順B: 倍率 r の拡大畳み込みを適用 → 必要ならダウンサンプリング (1/r)
- 結果が一致するのは **特定のフィルタ設計や境界条件を満たす場合のみ**
- 一般のCNNでは完全等価ではないが、近似的な理解として有用

> 図提案: 信号処理的なブロック図で A と B の対応関係を併記

---

## U-Net による解像度回復
CNN で一度縮小した後、失われた空間解像度を後半で取り戻すのは難しい $\rightarrow $これに対応したのが U-Net。

- 折り返し点で対称な層同士の出力を転送（スキップ接続）
- 転送された層出力を受け側の層入力と**チャネル方向に連結 (concat)**  
  → ResNetとは加算の計算方法が違う
- 低層の空間情報を直接高層に伝達して、復元性能を向上

> 図提案: `concat([encoder_feature, decoder_feature], axis=channels)` の図示

---

## シフト＆スティッチ（補足）
シフト＆スティッチも存在するが、効率が悪く実用性は低い。

> 備考: 実験比較として 1 スライドだけ触れるか、付録扱いにする選択肢

---

## 物体カテゴリ認識の適用例（ImageNet）
ImageNet は 1000 クラス・計約 128 万枚の画像からなるベンチマーク。
- 画像生成/補完系ではなく分類系だが、特徴抽出の理解に有用

> 図提案: クラス分布の概観や典型画像を 3×3 グリッドで

---

## AlexNet と層出力の可視化
教科書には AlexNet を用いた各層の出力やテスト結果が掲載されている。

- 低層: エッジ/テクスチャ、中層: パーツ、高層: カテゴリ概念
- 中間層の活性マップや誤分類例が人間にとっての理解を補助している

> 提案: 教科書図を引用（出典明記）し、層ごとの可視化を 2〜3 枚に分割
